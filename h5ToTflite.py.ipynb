{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bba5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model,Model\n",
    "from tensorflow.keras.layers import Input\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44e893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "model=load_model('.\\\\model.h5')\n",
    "config=model.get_config()\n",
    "print(config[\"layers\"][0][\"config\"][\"batch_input_shape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee18afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustData(img,mask,flag_multi_class,num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape + (num_class,))\n",
    "        for i in range(num_class):\n",
    "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
    "            #index = np.where(mask == i)\n",
    "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
    "            #new_mask[index_mask] = 1\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask /255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)\n",
    "\n",
    "\n",
    "def genTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
    "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for index,item in enumerate(image_name_arr):\n",
    "        img = io.imread(item,as_gray = image_as_gray)\n",
    "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
    "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
    "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr,mask_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190bbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train,imgs_mask_train = genTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "imgs_train=imgs_train.astype('float32')\n",
    "imgs_mask_train=imgs_mask_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4383c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "  for data in tf.data.Dataset.from_tensor_slices((imgs_train)).batch(1).take(30):\n",
    "    yield [data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be92d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\adikr\\AppData\\Local\\Temp\\tmprgim6jda\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\adikr\\AppData\\Local\\Temp\\tmprgim6jda\\assets\n",
      "C:\\Users\\adikr\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1914000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "fixed_input=Input((256,256,1))\n",
    "fixed_model=Model(fixed_input,model(fixed_input))\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()\n",
    "open(\"model.tflite\",\"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0a5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter=tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293ff215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_2:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 256, 256,   1]),\n",
       "  'shape_signature': array([ -1, 256, 256,   1]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.003921568859368563, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([-128]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6744a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 55,\n",
       "  'shape': array([  1, 256, 256,   1]),\n",
       "  'shape_signature': array([ -1, 256, 256,   1]),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.00390625, -128),\n",
       "  'quantization_parameters': {'scales': array([0.00390625], dtype=float32),\n",
       "   'zero_points': array([-128]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fb29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
